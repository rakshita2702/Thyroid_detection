# Install required libraries
!pip install catboost lightgbm scikit-learn umap-learn matplotlib seaborn xgboost joblib

# Import necessary libraries
import time
import pandas as pd
import numpy as np
import seaborn as sns
import matplotlib.pyplot as plt
from sklearn.preprocessing import LabelEncoder, StandardScaler
from sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV
from sklearn.metrics import accuracy_score, roc_curve, roc_auc_score, confusion_matrix
from sklearn.impute import SimpleImputer
from sklearn.decomposition import PCA
from xgboost import XGBClassifier
import joblib

# Load and preprocess the dataset
csv_file_path = "hypothyroid.csv"  # Adjust the file path as needed
df = pd.read_csv(csv_file_path)

# Remove rows containing missing values ("?")
df = df[(df != "?").all(axis=1)]

# Map binary columns
binary_cols = ['on thyroxine', 'query on thyroxine', 'on antithyroid medication',
               'sick', 'pregnant', 'thyroid surgery', 'I131 treatment',
               'query hypothyroid', 'query hyperthyroid', 'lithium',
               'goitre', 'tumor', 'hypopituitary', 'psych', 'TSH measured',
               'T3 measured', 'TT4 measured', 'T4U measured', 'FTI measured', 'TBG measured']
for col in binary_cols:
    df[col] = df[col].map({'t': 1, 'f': 0})

# Encode categorical columns
df['sex'] = df['sex'].map({'M': 1, 'F': 0})
df['binaryClass'] = df['binaryClass'].map({'P': 1, 'N': 0})
df['referral source'] = LabelEncoder().fit_transform(df['referral source'])

# Split data into features (X) and target (y)
X = df.drop('binaryClass', axis=1)
y = df['binaryClass']

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Handle missing values
imputer = SimpleImputer(strategy='most_frequent')
X_train = imputer.fit_transform(X_train)
X_test = imputer.transform(X_test)

# Standardize the data
scaler = StandardScaler()
X_train = scaler.fit_transform(X_train)
X_test = scaler.transform(X_test)

# Exploratory Data Analysis (EDA)
plt.figure(figsize=(6, 4))
sns.countplot(x='binaryClass', data=df)
plt.title('Class Distribution')
plt.show()

plt.figure(figsize=(6, 6))
df['binaryClass'].value_counts().plot(kind='pie', autopct='%1.1f%%')
plt.title('Class Distribution')
plt.show()

# Model Training - XGBoost Classifier
model_xgb = XGBClassifier(random_state=42, use_label_encoder=False, eval_metric='logloss')
model_xgb.fit(X_train, y_train)

# Model Evaluation
y_pred = model_xgb.predict(X_test)
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy * 100:.2f}%")

# Plotting ROC Curve
probs = model_xgb.predict_proba(X_test)[:, 1]
fpr, tpr, thresholds = roc_curve(y_test, probs)
plt.plot(fpr, tpr, label='XGBoost')
plt.xlabel('False Positive Rate')
plt.ylabel('True Positive Rate')
plt.title('ROC Curve')
plt.legend()
plt.show()

# Save the model
model_filename = 'xgb_model.pkl'
joblib.dump(model_xgb, model_filename)
print(f"Model saved as {model_filename}")

# Load the saved model (for verification)
loaded_model = joblib.load(model_filename)
y_pred_loaded = loaded_model.predict(X_test)
accuracy_loaded = accuracy_score(y_test, y_pred_loaded)
print(f"Accuracy of Loaded Model: {accuracy_loaded * 100:.2f}%")
